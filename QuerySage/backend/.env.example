# === LLM Provider Configuration ===
LLM_API_KEY=replace-with-your-actual-api-key
LLM_API_URL=https://api.your-llm.com/v1/chat/completions
LLM_MODEL=gpt-4o-mini          # or the model you plan to use
MAX_TOKENS=300                 # max tokens per response

# === PDF and FAISS Settings ===
PDF_PATH=dbms.pdf              # your PDF file
FAISS_PATH=index.faiss         # saved FAISS index file
EMB_PATH=embeddings.npy        # saved embeddings file
DOCS_PATH=docs.pkl             # saved documents pickle
EMB_MODEL=all-MiniLM-L6-v2     # embedding model to use

# === Server Settings ===
PORT=5000

# === Security ===
REINDEX_SECRET=dev-secret-key  # change to something strong
